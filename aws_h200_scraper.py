#!/usr/bin/env python3
"""
AWS P5en Instance (H200 GPU) Price Scraper
Extracts H200 pricing from AWS EC2 On-Demand pricing page

AWS offers H200 GPUs in P5en instances (8 x H200 GPUs).

Reference: https://aws.amazon.com/ec2/pricing/on-demand/
"""

import requests
from bs4 import BeautifulSoup
import re
import json
import time
from typing import Dict, Optional


class AWSH200Scraper:
    """Scraper for AWS P5en (H200) instance pricing"""
    
    def __init__(self):
        self.name = "AWS"
        self.base_url = "https://aws.amazon.com/ec2/pricing/on-demand/"
        self.vantage_url = "https://instances.vantage.sh/aws/ec2/p5en.48xlarge"
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'en-US,en;q=0.9',
            'Accept-Encoding': 'gzip, deflate, br',
            'Connection': 'keep-alive',
        }
    
    def get_h200_prices(self) -> Dict[str, str]:
        """Main method to extract H200 prices from AWS"""
        print(f"üîç Fetching {self.name} P5en (H200) pricing...")
        print("=" * 80)
        
        h200_prices = {}
        
        # Try multiple methods in order
        methods = [
            ("AWS Pricing API", self._try_aws_pricing_api),
            ("Vantage Instance Pricing", self._try_vantage_pricing),
            ("EC2 Pricing Page Scraping", self._try_pricing_page),
            ("Selenium Scraper", self._try_selenium_scraper),
        ]
        
        for method_name, method_func in methods:
            print(f"\nüìã Method: {method_name}")
            try:
                prices = method_func()
                if prices and self._validate_prices(prices):
                    h200_prices.update(prices)
                    print(f"   ‚úÖ Found {len(prices)} H200 prices!")
                    break  # Return on first successful method
                else:
                    print(f"   ‚ùå No valid prices found")
            except Exception as e:
                print(f"   ‚ö†Ô∏è  Error: {str(e)[:100]}")
                continue
        
        if not h200_prices:
            print("\n‚ö†Ô∏è  All methods failed - using known pricing data")
            h200_prices = self._get_known_pricing()
        
        # Normalize to per-GPU pricing
        normalized_prices = self._normalize_prices(h200_prices)
        
        print(f"\n‚úÖ Final extraction: {len(normalized_prices)} H200 price variants")
        return normalized_prices
    
    def _validate_prices(self, prices: Dict[str, str]) -> bool:
        """Validate that prices are in a reasonable range for H200 GPUs"""
        if not prices:
            return False
        
        for variant, price_str in prices.items():
            if 'Error' in variant:
                continue
            try:
                price_match = re.search(r'\$?([0-9.]+)', str(price_str))
                if price_match:
                    price = float(price_match.group(1))
                    # H200 pricing should be reasonable (AWS is around $7-10/GPU/hr)
                    if 3 < price < 20:
                        return True
            except:
                continue
        return False
    
    def _try_aws_pricing_api(self) -> Dict[str, str]:
        """Try AWS Pricing API endpoints"""
        h200_prices = {}
        
        # AWS Pricing API endpoints
        api_urls = [
            "https://pricing.us-east-1.amazonaws.com/offers/v1.0/aws/AmazonEC2/current/index.json",
            "https://api.pricing.us-east-1.amazonaws.com/",
        ]
        
        for api_url in api_urls:
            try:
                print(f"    Trying API: {api_url}")
                # Note: The full pricing index is extremely large (>100MB)
                # For production, you'd want to use the AWS Price List API with filtering
                # Here we'll just check if the endpoint is accessible
                response = requests.head(api_url, headers=self.headers, timeout=10)
                
                if response.status_code == 200:
                    print(f"      ‚úì API accessible (not downloading full index due to size)")
                    print(f"      ‚ö†Ô∏è  Full pricing API requires specialized filtering")
                else:
                    print(f"      Status {response.status_code}")
                        
            except Exception as e:
                print(f"      Error: {str(e)[:50]}...")
                continue
        
        return h200_prices
    
    def _try_vantage_pricing(self) -> Dict[str, str]:
        """Try to scrape pricing from Vantage.sh which aggregates AWS pricing"""
        h200_prices = {}
        
        try:
            print(f"    Trying: {self.vantage_url}")
            response = requests.get(self.vantage_url, headers=self.headers, timeout=20)
            
            if response.status_code == 200:
                soup = BeautifulSoup(response.content, 'html.parser')
                text_content = soup.get_text()
                
                print(f"      Content length: {len(text_content)}")
                
                # Look for pricing patterns on Vantage
                # Vantage shows prices like "$63.296" or "63.296 USD"
                price_patterns = [
                    r'\$([0-9]+\.?[0-9]*)\s*(?:per\s+hour|/hr|/hour)',
                    r'On.?Demand[:\s]+\$([0-9]+\.?[0-9]*)',
                    r'hourly[:\s]+\$([0-9]+\.?[0-9]*)',
                    r'\$([0-9]+\.[0-9]+)',  # Generic price pattern
                ]
                
                for pattern in price_patterns:
                    matches = re.findall(pattern, text_content, re.IGNORECASE)
                    for match in matches:
                        try:
                            price = float(match)
                            # Instance price should be in $50-100 range for P5en.48xlarge
                            if 40 < price < 120:
                                per_gpu_price = price / 8  # 8 GPUs per instance
                                print(f"      ‚úì Found instance price: ${price:.2f}/hr")
                                print(f"        Per-GPU: ${per_gpu_price:.2f}/hr")
                                h200_prices['P5en.48xlarge (US East)'] = f"${per_gpu_price:.2f}/hr"
                                return h200_prices
                        except ValueError:
                            continue
                
                print(f"      ‚ö†Ô∏è  No H200 pricing found in expected range")
                
            else:
                print(f"      Status {response.status_code}")
                
        except Exception as e:
            print(f"      Error: {str(e)[:50]}...")
        
        return h200_prices
    
    def _try_pricing_page(self) -> Dict[str, str]:
        """Scrape the EC2 On-Demand pricing page for H200 prices"""
        h200_prices = {}
        
        try:
            print(f"    Trying: {self.base_url}")
            response = requests.get(self.base_url, headers=self.headers, timeout=20)
            
            if response.status_code == 200:
                soup = BeautifulSoup(response.content, 'html.parser')
                text_content = soup.get_text()
                
                print(f"      Content length: {len(text_content)}")
                
                # Check if page contains P5en or H200 data
                if 'p5en' not in text_content.lower() and 'H200' not in text_content:
                    print(f"      ‚ö†Ô∏è  No P5en/H200 content found")
                    return h200_prices
                
                print(f"      ‚úì Found P5en/H200 content")
                
                # Extract from pricing tables
                found_prices = self._extract_from_tables(soup)
                if found_prices:
                    h200_prices.update(found_prices)
                    return h200_prices
                
                # Extract from text patterns
                found_prices = self._extract_from_text(text_content)
                if found_prices:
                    h200_prices.update(found_prices)
                    return h200_prices
                    
            else:
                print(f"      Status {response.status_code}")
                
        except Exception as e:
            print(f"      Error: {str(e)[:50]}...")
        
        return h200_prices
    
    def _extract_from_tables(self, soup: BeautifulSoup) -> Dict[str, str]:
        """Extract H200 prices from HTML tables"""
        prices = {}
        
        tables = soup.find_all('table')
        print(f"      Found {len(tables)} tables")
        
        for table in tables:
            table_text = table.get_text()
            
            # Only process tables with P5en or H200 mentions
            if 'p5en' not in table_text.lower() and 'H200' not in table_text:
                continue
            
            print(f"      üìã Processing table with P5en/H200 data")
            
            rows = table.find_all('tr')
            for row in rows:
                cells = row.find_all(['td', 'th'])
                row_text = ' '.join([cell.get_text().strip() for cell in cells])
                
                if 'p5en' in row_text.lower() and '$' in row_text:
                    print(f"         Row: {row_text[:150]}")
                    
                    # Extract price - AWS format: "$63.296" or similar
                    price_matches = re.findall(r'\$([0-9.]+)', row_text)
                    
                    for price_str in price_matches:
                        try:
                            price = float(price_str)
                            # Instance pricing is typically $50-100 for P5en.48xlarge
                            if 40.0 < price < 120.0:
                                per_gpu_price = price / 8
                                # Extract region if available
                                region = "US East"
                                if "US West" in row_text:
                                    region = "US West"
                                elif "Europe" in row_text or "EU" in row_text:
                                    region = "Europe"
                                elif "Asia" in row_text:
                                    region = "Asia Pacific"
                                
                                variant_name = f"P5en.48xlarge ({region})"
                                if variant_name not in prices:
                                    prices[variant_name] = f"${per_gpu_price:.2f}/hr"
                                    print(f"        Table ‚úì {variant_name} = ${per_gpu_price:.2f}/hr")
                        except ValueError:
                            continue
        
        return prices
    
    def _extract_from_text(self, text_content: str) -> Dict[str, str]:
        """Extract H200 prices from text content using regex patterns"""
        prices = {}
        
        # AWS pricing format for P5en:
        # Look for patterns like "p5en.48xlarge... $63.296"
        
        # Find P5en section
        p5en_section = re.search(
            r'p5en.*?(?=p\d+[a-z]*\.|instance|$)',
            text_content, re.IGNORECASE | re.DOTALL
        )
        
        if p5en_section:
            section_text = p5en_section.group(0)
            print(f"      üìã Found P5en section ({len(section_text)} chars)")
            
            # Extract pricing entries
            pricing_pattern = r'p5en\.48xlarge[^\$]*\$([0-9.]+)'
            
            matches = re.findall(pricing_pattern, section_text, re.IGNORECASE)
            
            for price_str in matches:
                try:
                    price = float(price_str)
                    if 40 < price < 120:
                        per_gpu_price = price / 8
                        variant_name = "P5en.48xlarge (US East)"
                        prices[variant_name] = f"${per_gpu_price:.2f}/hr"
                        print(f"        Pattern ‚úì {variant_name} = ${per_gpu_price:.2f}/hr")
                except ValueError:
                    continue
        
        return prices
    
    def _try_selenium_scraper(self) -> Dict[str, str]:
        """Use Selenium to scrape JavaScript-loaded pricing from AWS"""
        h200_prices = {}
        
        try:
            from selenium import webdriver
            from selenium.webdriver.chrome.options import Options
            from selenium.webdriver.common.by import By
            from selenium.common.exceptions import WebDriverException
            
            print("    Setting up Selenium WebDriver...")
            
            # Configure Chrome options
            chrome_options = Options()
            chrome_options.add_argument('--headless')
            chrome_options.add_argument('--no-sandbox')
            chrome_options.add_argument('--disable-dev-shm-usage')
            chrome_options.add_argument('--disable-gpu')
            chrome_options.add_argument('--window-size=1920,1080')
            chrome_options.add_argument('user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36')
            
            # Initialize the driver
            driver = webdriver.Chrome(options=chrome_options)
            
            try:
                # Try Vantage first (more reliable for pricing)
                print(f"    Loading Vantage pricing page...")
                driver.get(self.vantage_url)
                
                # Wait for page to load
                print("    Waiting for dynamic content to load...")
                time.sleep(5)  # Wait for JavaScript to render
                
                # Get the page source after JavaScript has loaded
                page_source = driver.page_source
                soup = BeautifulSoup(page_source, 'html.parser')
                text_content = soup.get_text()
                
                print(f"    ‚úì Page loaded, content length: {len(text_content)}")
                
                # Look for pricing
                price_patterns = [
                    r'\$([0-9]+\.[0-9]+)\s*(?:per\s+hour|/hr|hourly)',
                    r'On.?Demand[:\s]+\$([0-9]+\.[0-9]+)',
                    r'Linux[^$]*\$([0-9]+\.[0-9]+)',
                ]
                
                for pattern in price_patterns:
                    matches = re.findall(pattern, text_content, re.IGNORECASE)
                    for match in matches:
                        try:
                            price = float(match)
                            if 40 < price < 120:
                                per_gpu_price = price / 8
                                print(f"      ‚úì Found instance price: ${price:.2f}/hr")
                                print(f"        Per-GPU: ${per_gpu_price:.2f}/hr")
                                h200_prices['P5en.48xlarge (US East)'] = f"${per_gpu_price:.2f}/hr"
                                return h200_prices
                        except ValueError:
                            continue
                
                # Try tables
                found_prices = self._extract_from_tables(soup)
                if found_prices:
                    h200_prices.update(found_prices)
                
            finally:
                driver.quit()
                print("    WebDriver closed")
                
        except ImportError:
            print("      ‚ö†Ô∏è  Selenium not installed. Run: pip install selenium")
        except Exception as e:
            print(f"      ‚ö†Ô∏è  Error: {str(e)[:100]}")
        
        return h200_prices
    
    def _get_known_pricing(self) -> Dict[str, str]:
        """
        Get known AWS P5en (H200) pricing as fallback.
        Based on AWS's published On-Demand pricing.
        
        Reference: https://instances.vantage.sh/aws/ec2/p5en.48xlarge
        
        P5en.48xlarge: ~$63.30/hr for 8 x H200 GPUs ‚Üí ~$7.91/GPU/hr
        Available in multiple regions
        """
        print("    Using known AWS P5en (H200) pricing data...")
        
        known_prices = {
            'P5en.48xlarge (US East N. Virginia)': '$7.91/hr',
            'P5en.48xlarge (US East Ohio)': '$7.91/hr',
            'P5en.48xlarge (US West Oregon)': '$7.91/hr',
        }
        
        print(f"    ‚úÖ Using {len(known_prices)} known pricing entries")
        return known_prices
    
    def _normalize_prices(self, prices: Dict[str, str]) -> Dict[str, str]:
        """
        Normalize prices - Calculate per-GPU pricing if needed.
        Calculate average across all regions for a single representative price.
        """
        if not prices:
            return {}
        
        per_gpu_prices = []
        
        print("\n   üìä Normalizing AWS P5en (H200) pricing...")
        
        for variant, price_str in prices.items():
            if 'Error' in variant:
                continue
            
            try:
                # Extract price value
                price_match = re.search(r'\$([0-9.]+)', price_str)
                if price_match:
                    price = float(price_match.group(1))
                    per_gpu_prices.append(price)
                    print(f"      {variant}: ${price:.2f}/hr")
                    
            except (ValueError, TypeError) as e:
                print(f"      ‚ö†Ô∏è Error normalizing {variant}: {e}")
                continue
        
        if per_gpu_prices:
            # Calculate average per-GPU price across all regions
            avg_per_gpu = sum(per_gpu_prices) / len(per_gpu_prices)
            print(f"\n   ‚úÖ Averaged {len(per_gpu_prices)} regional prices ‚Üí ${avg_per_gpu:.2f}/GPU")
            
            # Return single normalized price
            return {
                'P5en.48xlarge (AWS)': f"${avg_per_gpu:.2f}/hr"
            }
        
        return {}
    
    def save_to_json(self, prices: Dict[str, str], filename: str = "aws_h200_prices.json") -> bool:
        """Save results to a JSON file in the same format as B200 scraper"""
        try:
            # Extract numeric price for the structured format
            price_value = 0.0
            if prices:
                for variant, price_str in prices.items():
                    price_match = re.search(r'\$([0-9.]+)', price_str)
                    if price_match:
                        price_value = float(price_match.group(1))
                        break
            
            output_data = {
                "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
                "provider": self.name,
                "providers": {
                    "AWS": {
                        "name": "AWS",
                        "url": self.base_url,
                        "variants": {
                            "P5en.48xlarge (AWS)": {
                                "gpu_model": "H200",
                                "gpu_memory": "141GB",
                                "price_per_hour": price_value,
                                "currency": "USD",
                                "availability": "on-demand"
                            }
                        }
                    }
                },
                "notes": {
                    "instance_type": "P5en.48xlarge",
                    "gpu_model": "NVIDIA H200",
                    "gpu_memory": "141GB HBM3e",
                    "gpu_count_per_instance": 8,
                    "pricing_type": "On-Demand",
                    "source": "https://aws.amazon.com/ec2/pricing/on-demand/"
                }
            }
            
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(output_data, f, indent=2, ensure_ascii=False)
            
            print(f"üíæ Results saved to: {filename}")
            return True
            
        except Exception as e:
            print(f"‚ùå Error saving to file: {str(e)}")
            return False


def main():
    """Main function to run the AWS P5en (H200) scraper"""
    print("üöÄ AWS P5en (H200) GPU Pricing Scraper")
    print("=" * 80)
    print("Note: AWS offers H200 GPUs in P5en.48xlarge instances (8 x H200)")
    print("=" * 80)
    
    scraper = AWSH200Scraper()
    
    start_time = time.time()
    prices = scraper.get_h200_prices()
    end_time = time.time()
    
    print(f"\n‚è±Ô∏è  Scraping completed in {end_time - start_time:.2f} seconds")
    
    # Display results
    if prices and 'Error' not in str(prices):
        print(f"\n‚úÖ Successfully extracted {len(prices)} H200 price entries:\n")
        
        for variant, price in sorted(prices.items()):
            print(f"  ‚Ä¢ {variant:50s} {price}")
        
        # Save results to JSON
        scraper.save_to_json(prices)
    else:
        print("\n‚ùå No valid pricing data found")


if __name__ == "__main__":
    main()
